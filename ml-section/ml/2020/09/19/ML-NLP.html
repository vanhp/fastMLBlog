<!DOCTYPE html>
<html lang="en"><head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="twitter:card" content="summary" /><!-- Begin Jekyll SEO tag v2.6.1 -->
<title>Natural Language Process in Machine Learning | Supra_PolyglotCoder</title>
<meta name="generator" content="Jekyll v4.0.0" />
<meta property="og:title" content="Natural Language Process in Machine Learning" />
<meta name="author" content="Vanh Phomsavanh" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="How machine learning work with Human Language" />
<meta property="og:description" content="How machine learning work with Human Language" />
<link rel="canonical" href="https://www.vanhp.com/ml-section/ml/2020/09/19/ML-NLP.html" />
<meta property="og:url" content="https://www.vanhp.com/ml-section/ml/2020/09/19/ML-NLP.html" />
<meta property="og:site_name" content="Supra_PolyglotCoder" />
<meta property="og:image" content="https://www.vanhp.com/ML-section/assets/images/neuralNet1.jpg" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2020-09-19T00:00:00-05:00" />
<script type="application/ld+json">
{"author":{"@type":"Person","name":"Vanh Phomsavanh"},"description":"How machine learning work with Human Language","dateModified":"2020-09-19T00:00:00-05:00","datePublished":"2020-09-19T00:00:00-05:00","headline":"Natural Language Process in Machine Learning","@type":"BlogPosting","mainEntityOfPage":{"@type":"WebPage","@id":"https://www.vanhp.com/ml-section/ml/2020/09/19/ML-NLP.html"},"image":"https://www.vanhp.com/ML-section/assets/images/neuralNet1.jpg","url":"https://www.vanhp.com/ml-section/ml/2020/09/19/ML-NLP.html","@context":"https://schema.org"}</script>
<!-- End Jekyll SEO tag -->
<link rel="stylesheet" href="/assets/css/style.css"><link type="application/atom+xml" rel="alternate" href="https://www.vanhp.com/feed.xml" title="Supra_PolyglotCoder" /><link rel="shortcut icon" type="image/x-icon" href="/images/favicon.ico"><!-- Begin Jekyll SEO tag v2.6.1 -->
<title>Natural Language Process in Machine Learning | Supra_PolyglotCoder</title>
<meta name="generator" content="Jekyll v4.0.0" />
<meta property="og:title" content="Natural Language Process in Machine Learning" />
<meta name="author" content="Vanh Phomsavanh" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="How machine learning work with Human Language" />
<meta property="og:description" content="How machine learning work with Human Language" />
<link rel="canonical" href="https://www.vanhp.com/ml-section/ml/2020/09/19/ML-NLP.html" />
<meta property="og:url" content="https://www.vanhp.com/ml-section/ml/2020/09/19/ML-NLP.html" />
<meta property="og:site_name" content="Supra_PolyglotCoder" />
<meta property="og:image" content="https://www.vanhp.com/ML-section/assets/images/neuralNet1.jpg" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2020-09-19T00:00:00-05:00" />
<script type="application/ld+json">
{"author":{"@type":"Person","name":"Vanh Phomsavanh"},"description":"How machine learning work with Human Language","dateModified":"2020-09-19T00:00:00-05:00","datePublished":"2020-09-19T00:00:00-05:00","headline":"Natural Language Process in Machine Learning","@type":"BlogPosting","mainEntityOfPage":{"@type":"WebPage","@id":"https://www.vanhp.com/ml-section/ml/2020/09/19/ML-NLP.html"},"image":"https://www.vanhp.com/ML-section/assets/images/neuralNet1.jpg","url":"https://www.vanhp.com/ml-section/ml/2020/09/19/ML-NLP.html","@context":"https://schema.org"}</script>
<!-- End Jekyll SEO tag -->

<link href="https://unpkg.com/@primer/css/dist/primer.css" rel="stylesheet" />
<link rel="stylesheet" href="//use.fontawesome.com/releases/v5.0.7/css/all.css"><link type="application/atom+xml" rel="alternate" href="https://www.vanhp.com/feed.xml" title="Supra_PolyglotCoder" />
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.11.1/dist/katex.min.css" integrity="sha384-zB1R0rpPzHqg7Kpt0Aljp8JPLqbXI3bhnPWROx27a9N0Ll6ZP/+DiW/UqRcLbRjq" crossorigin="anonymous">
    <script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_CHTML"> </script>
    <script src="https://cdn.jsdelivr.net/npm/katex@0.11.1/dist/katex.min.js" integrity="sha384-y23I5Q6l+B6vatafAwxRu/0oK/79VlbSz7Q9aiSZUvyWYIYsd+qj+o24G5ZU2zJz" crossorigin="anonymous"></script>
    <script src="https://cdn.jsdelivr.net/npm/katex@0.11.1/dist/contrib/auto-render.min.js" integrity="sha384-kWPLUVMOks5AQFrykwIup5lo0m3iMkkHrD0uJ4H5cjeGihAutqP0yW0J6dpFiVkI" crossorigin="anonymous"></script>
    <script>
    document.addEventListener("DOMContentLoaded", function() {
        renderMathInElement( document.body, {
        delimiters: [
            {left: "$$", right: "$$", display: true},
            {left: "[%", right: "%]", display: true},
            {left: "$", right: "$", display: false}
        ]}
        );
    });
    </script>


<script>
function wrap_img(fn) {
    if (document.attachEvent ? document.readyState === "complete" : document.readyState !== "loading") {
        var elements = document.querySelectorAll(".post img");
        Array.prototype.forEach.call(elements, function(el, i) {
            if (el.getAttribute("title") && (el.className != "emoji")) {
                const caption = document.createElement('figcaption');
                var node = document.createTextNode(el.getAttribute("title"));
                caption.appendChild(node);
                const wrapper = document.createElement('figure');
                wrapper.className = 'image';
                el.parentNode.insertBefore(wrapper, el);
                el.parentNode.removeChild(el);
                wrapper.appendChild(el);
                wrapper.appendChild(caption);
            }
        });
    } else { document.addEventListener('DOMContentLoaded', fn); }
}
window.onload = wrap_img;
</script>

<script>
    document.addEventListener("DOMContentLoaded", function(){
    // add link icon to anchor tags
    var elem = document.querySelectorAll(".anchor-link")
    elem.forEach(e => (e.innerHTML = '<i class="fas fa-link fa-xs"></i>'));
    });
</script>
</head>
<body><header class="site-header" role="banner">

  <div class="wrapper"><!--
      edit by vanh original code header.html
    <a class="site-title" rel="author" href="/">Supra_PolyglotCoder</a>
    replace with custom code below
    -->
    <a class="site-title" rel="author" href="/"><img src="/images/gradlogo1.jpg" alt="Supra_PolyglotCoder"></img></a><nav class="site-nav">
        <input type="checkbox" id="nav-trigger" class="nav-trigger" />
        <label for="nav-trigger">
          <span class="menu-icon">
            <svg viewBox="0 0 18 15" width="18px" height="15px">
              <path d="M18,1.484c0,0.82-0.665,1.484-1.484,1.484H1.484C0.665,2.969,0,2.304,0,1.484l0,0C0,0.665,0.665,0,1.484,0 h15.032C17.335,0,18,0.665,18,1.484L18,1.484z M18,7.516C18,8.335,17.335,9,16.516,9H1.484C0.665,9,0,8.335,0,7.516l0,0 c0-0.82,0.665-1.484,1.484-1.484h15.032C17.335,6.031,18,6.696,18,7.516L18,7.516z M18,13.516C18,14.335,17.335,15,16.516,15H1.484 C0.665,15,0,14.335,0,13.516l0,0c0-0.82,0.665-1.483,1.484-1.483h15.032C17.335,12.031,18,12.695,18,13.516L18,13.516z"/>
            </svg>
          </span>
        </label>

        <div class="trigger"><a class="page-link" href="/about/">About Me</a><a class="page-link" href="/Resource-section/">Resources</a><a class="page-link" href="/ML-section/">ML</a><a class="page-link" href="/Coding-section/">Programming</a><a class="page-link" href="/search/">Search</a><a class="page-link" href="/categories/">Tags</a></div>
      </nav></div>
</header>
<main class="page-content" aria-label="Content">
      <div class="wrapper">
        <article class="post h-entry" itemscope itemtype="http://schema.org/BlogPosting">

  <header class="post-header">
    <!-- add feature image on top of post --><img src="/ML-section/assets/images/neuralNet1.jpg" alt="" class="featured-image-post" /><h1 class="post-title p-name" itemprop="name headline">Natural Language Process in Machine Learning</h1><p class="page-description">How machine learning work with Human Language</p><p class="post-meta post-meta-title"><time class="dt-published" datetime="2020-09-19T00:00:00-05:00" itemprop="datePublished">
        Sep 19, 2020
      </time>
       • <span class="read-time" title="Estimated read time">
    
    
      5 min read
    
</span></p>

    
      <p class="category-tags"><i class="fas fa-tags category-tags-icon"></i></i> 
      
        <a class="category-tags-link" href="/categories/#ML-section">ML-section</a>
        &nbsp;
      
        <a class="category-tags-link" href="/categories/#ML">ML</a>
        
      
      </p>
    

    </header>

  <div class="post-content e-content" itemprop="articleBody">
    <!-- ![](/ML-section/assets/images/neuralNet1.jpg) -->

<h2 id="nlp-deep-dive-rnn">NLP Deep Dive: RNN</h2>
<p>Language Model is model that train to predict the next in the sentence in the text would be. This type of model is called self-supervise model since it’s doesn’t require label to guide it’s prediction by compare the prediction against the actual label which is the ground truth. It simply learn from the dataset in this case is text and hugh amount of texts. It has it own highly complicate woy of extract the label from the data. It’s also has its own way to understand the context in the language that it works with.
Self-supervise is a highly active field in research community. Since is applicable in many domains other than text.</p>

<h3 id="pretrained-nlp-model">Pretrained NLP Model</h3>
<p>Using pretrained Language model is widely used instead of train them from scratch since it’s highly resource and time-consuming. A pretrained language model in one task maybe retrain on different task e.g. retrain a model that was trained in Wikipedia on movies reviews database such as IMDb. As with all pretrained model it’s helpful to get insign into the dataset and familar with the style of data e.g. techical,formal,casual type.</p>

<h3 id="the-ulmfit-approach">The ULMFit approach</h3>
<p>Have a good understanding of the language model foundation is useful to adapt and fine-tuning the pretrained model for new task that may not easily relate to original task. This technique of adapting or refining the pretrained model with data relate to new task prior to training it for the new task (do classification) is call Universal Language Model Fine-tuning. The <a href="https://arxiv.org/abs/1801.06146">ULMFIt</a> paper indicate that this help improve the performance of the model remarkedbly.
<img src="/images/ulmfit1.png" alt="ulmfit_step" /></p>

<h3 id="text-preprocessing">Text preprocessing</h3>

<p>From knowledge of using categorical variables as an independent variable for NN.</p>

<ul>
  <li>Make a list of all possible levels (words) of that categorical variable (we’ll call this list the vocab).</li>
  <li>Replace each level (word) with its index in the vocab.</li>
  <li>Create an embedding matrix for this containing a row for each level(word) (i.e., for each item of the vocab).</li>
  <li>Use this embedding matrix as the first layer of a neural network. (A dedicated embedding matrix can take as inputs the raw vocab indexes created in step 2; this is equivalent to but faster and more efficient than a matrix that takes as input one-hot-encoded vectors representing the indexes.)</li>
</ul>

<p>These are the basic approach for dealing with text with the exception of text has sequence to deal with sequence in text</p>
<ol>
  <li>concaternate all of the document in the dataset into one giant long string.</li>
  <li>split the string into list of words</li>
  <li>assign the independent variable as the sequence of words start from first word to second to last word</li>
  <li>assign the dependent variable as the sequence of words start from second word ending at last word this will create an offset by 1 of independent variable and dependent variable</li>
</ol>

<p>The vocab will contain both old words that were used to pretrain the model and new words that we’ve just created which the exception that new words won’t have any corresponding embedding matrix which will be filled with random value.
the prodcess of create vocab:</p>
<ol>
  <li>tokenize the text by convert them into words</li>
  <li>Numericalize by assign the new unique word an index (int) value</li>
  <li>create a loader to these data with LMDataLoader class from fastai</li>
  <li>create language model with RNN that can handle arbitrary size input list</li>
</ol>

<h3 id="jagons">Jagons:</h3>
<ul>
  <li>Self-supervised learning: Training a model using labels that are embedded in the independent variable, rather than requiring external labels</li>
  <li>a word is a categorical variable</li>
  <li>corpus: database of text</li>
  <li>vocab: database of text that have been indexed</li>
  <li>Tokenization:: Convert the text into a list of words (or characters, or substrings, depending on the granularity of your model)</li>
  <li>Numericalization:: Make a list of all of the unique words that appear (the vocab), and convert each word into a number, by looking up its index in the vocab</li>
  <li>Language model data loader creation:: fastai provides an LMDataLoader class which automatically handles creating a dependent variable that is offset from the independent variable by one token. It also handles some important details, such as how to shuffle the training data in such a way that the dependent and independent variables maintain their structure as required</li>
  <li>Language model creation:: We need a special kind of model that does something we haven’t seen before: handles input lists which could be arbitrarily big or small. There are a number of ways to do this; in this chapter we will be using a recurrent neural network (RNN). We will get to the details of these RNNs in the &lt;&gt;, but for now, you can think of it as just another deep neural network.</li>
  <li>RNN: recurrent neural network a kind of neural network that have momory to handle long sequence of text</li>
</ul>

<hr />
<p>Jekyll requires blog post files to be named according to the following format:</p>

<p><code class="highlighter-rouge">YEAR-MONTH-DAY-filename.md</code></p>

<p>Where <code class="highlighter-rouge">YEAR</code> is a four-digit number, <code class="highlighter-rouge">MONTH</code> and <code class="highlighter-rouge">DAY</code> are both two-digit numbers, and <code class="highlighter-rouge">filename</code> is whatever file name you choose, to remind yourself what this post is about. <code class="highlighter-rouge">.md</code> is the file extension for markdown files.</p>

<p>The first line of the file should start with a single hash character, then a space, then your title. This is how you create a “<em>level 1 heading</em>” in markdown. Then you can create level 2, 3, etc headings as you wish but repeating the hash character, such as you see in the line <code class="highlighter-rouge">## File names</code> above.</p>

<h2 id="basic-formatting">Basic formatting</h2>

<p>You can use <em>italics</em>, <strong>bold</strong>, <code class="highlighter-rouge">code font text</code>, and create <a href="https://www.markdownguide.org/cheat-sheet/">links</a>. Here’s a footnote <sup id="fnref:1" role="doc-noteref"><a href="#fn:1" class="footnote">1</a></sup>. Here’s a horizontal rule:</p>

<hr />

<h2 id="lists">Lists</h2>

<p>Here’s a list:</p>

<ul>
  <li>item 1</li>
  <li>item 2</li>
</ul>

<p>And a numbered list:</p>

<ol>
  <li>item 1</li>
  <li>item 2</li>
</ol>

<h2 id="boxes-and-stuff">Boxes and stuff</h2>

<blockquote>
  <p>This is a quotation</p>
</blockquote>

<div class="Toast Toast--warning googoo">
   <span class="Toast-icon"><svg class="octicon octicon-alert octicon octicon-alert octicon octicon-alert octicon octicon-alert octicon octicon-alert octicon octicon-alert octicon octicon-alert octicon octicon-alert octicon octicon-alert octicon octicon-alert" viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M8.893 1.5c-.183-.31-.52-.5-.887-.5s-.703.19-.886.5L.138 13.499a.98.98 0 000 1.001c.193.31.53.501.886.501h13.964c.367 0 .704-.19.877-.5a1.03 1.03 0 00.01-1.002L8.893 1.5zm.133 11.497H6.987v-2.003h2.039v2.003zm0-3.004H6.987V5.987h2.039v4.006z"></path></svg></span>
   <span class="Toast-content">You can include alert boxes</span>
</div>

<p>…and…</p>

<div class="Toast">
   <span class="Toast-icon"><svg class="octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info" viewBox="0 0 14 16" version="1.1" width="14" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M6.3 5.69a.942.942 0 01-.28-.7c0-.28.09-.52.28-.7.19-.18.42-.28.7-.28.28 0 .52.09.7.28.18.19.28.42.28.7 0 .28-.09.52-.28.7a1 1 0 01-.7.3c-.28 0-.52-.11-.7-.3zM8 7.99c-.02-.25-.11-.48-.31-.69-.2-.19-.42-.3-.69-.31H6c-.27.02-.48.13-.69.31-.2.2-.3.44-.31.69h1v3c.02.27.11.5.31.69.2.2.42.31.69.31h1c.27 0 .48-.11.69-.31.2-.19.3-.42.31-.69H8V7.98v.01zM7 2.3c-3.14 0-5.7 2.54-5.7 5.68 0 3.14 2.56 5.7 5.7 5.7s5.7-2.55 5.7-5.7c0-3.15-2.56-5.69-5.7-5.69v.01zM7 .98c3.86 0 7 3.14 7 7s-3.14 7-7 7-7-3.12-7-7 3.14-7 7-7z"></path></svg></span>
   <span class="Toast-content">You can include info boxes</span>
</div>

<h2 id="images">Images</h2>

<p><img src="/images/logo.png" alt="" title="fast.ai's logo" /></p>

<h2 id="code">Code</h2>

<p>You can format text and code per usual</p>

<p>General preformatted text:</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code># Do a thing
do_thing()
</code></pre></div></div>

<p>Python code and output:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Prints '2'
</span><span class="k">print</span><span class="p">(</span><span class="mi">1</span><span class="o">+</span><span class="mi">1</span><span class="p">)</span>
</code></pre></div></div>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>2
</code></pre></div></div>

<p>Formatting text as shell commands:</p>

<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nb">echo</span> <span class="s2">"hello world"</span>
./some_script.sh <span class="nt">--option</span> <span class="s2">"value"</span>
wget https://example.com/cat_photo1.png
</code></pre></div></div>

<p>Formatting text as YAML:</p>

<div class="language-yaml highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="na">key</span><span class="pi">:</span> <span class="s">value</span>
<span class="pi">-</span> <span class="na">another_key</span><span class="pi">:</span> <span class="s2">"</span><span class="s">another</span><span class="nv"> </span><span class="s">value"</span>
</code></pre></div></div>

<h2 id="tables">Tables</h2>

<table>
  <thead>
    <tr>
      <th>Column 1</th>
      <th>Column 2</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>A thing</td>
      <td>Another thing</td>
    </tr>
  </tbody>
</table>

<h2 id="tweetcards">Tweetcards</h2>

<div class="jekyll-twitter-plugin"><blockquote class="twitter-tweet"><p lang="en" dir="ltr">Altair 4.0 is released! <a href="https://t.co/PCyrIOTcvv">https://t.co/PCyrIOTcvv</a><br />Try it with:<br /><br />  pip install -U altair<br /><br />The full list of changes is at <a href="https://t.co/roXmzcsT58">https://t.co/roXmzcsT58</a> ...read on for some highlights. <a href="https://t.co/vWJ0ZveKbZ">pic.twitter.com/vWJ0ZveKbZ</a></p>&mdash; Jake VanderPlas (@jakevdp) <a href="https://twitter.com/jakevdp/status/1204765621767901185?ref_src=twsrc%5Etfw">December 11, 2019</a></blockquote>
<script async="" src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>
</div>

<h2 id="footnotes">Footnotes</h2>

<div class="footnotes" role="doc-endnotes">
  <ol>
    <li id="fn:1" role="doc-endnote">
      <p>This is the footnote. <a href="#fnref:1" class="reversefootnote" role="doc-backlink">&#8617;</a></p>
    </li>
  </ol>
</div>

   
  </div><a class="u-url" href="/ml-section/ml/2020/09/19/ML-NLP.html" hidden></a>
</article>
      </div>
    </main><footer class="site-footer h-card">
  <data class="u-url" href="/"></data>

  <div class="wrapper">

    <h2 class="footer-heading">Supra_PolyglotCoder</h2>

    <div class="footer-col-wrapper">
      <div class="footer-col footer-col-1">
        <ul class="contact-list">
          <li class="p-name">Vanh Phomsavanh</li><li><a class="u-email" href="mailto:vanhphom@gmail.com">vanhphom@gmail.com</a></li>
            <li>&copy; VSP LLC 2020 </li></ul>
      </div>

      <div class="footer-col footer-col-2"><ul class="social-media-list"><li><a href="https://www.twitter.com/SupraCoder"><svg class="svg-icon"><use xlink:href="/assets/minima-social-icons.svg#twitter"></use></svg> <span class="username">SupraCoder</span></a></li><li><a href="https://github.com/vanhp"><svg class="svg-icon"><use xlink:href="/assets/minima-social-icons.svg#github"></use></svg> <span class="username">vanhp</span></a></li><li><a href="https://www.facebook.com/vanh+phom"><svg class="svg-icon"><use xlink:href="/assets/minima-social-icons.svg#facebook"></use></svg> <span class="username">vanh phom</span></a></li><li><a href="https://www.linkedin.com/in/vanh-phomsavanh-1bba668"><svg class="svg-icon"><use xlink:href="/assets/minima-social-icons.svg#linkedin"></use></svg> <span class="username">vanh-phomsavanh-1bba668</span></a></li></ul>
</div>

      <div class="footer-col footer-col-3">
        <p>A blog about my journey into Machine Learning and coding experience in general</p>
      </div>
    </div>

  </div>

</footer>
</body>

</html>
